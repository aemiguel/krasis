================================================================
Krasis Benchmark — 2026-02-17 12:15:26
================================================================
Model:            Qwen3-Coder-Next
Architecture:     qwen3_next, 48 layers, 512 experts, top-10, 12 GQA + 36 linear
PP Partition:     [48] (1 GPUs)

Hardware:
  CPU:            AMD EPYC 7742 64-Core Processor (64 cores)
  RAM:            995 GB total, 77.8 GB used by process
  GPU 0:          NVIDIA RTX 2000 Ada Generation (16380 MB), 11211 MB allocated
  GPU 1:          NVIDIA RTX 2000 Ada Generation (16380 MB), N/A
  GPU 2:          NVIDIA RTX 2000 Ada Generation (16380 MB), N/A

Quantization:
  GPU experts:    INT4 (Marlin)
  CPU experts:    INT4
  Attention:      INT8
  Shared expert:  INT8
  Dense MLP:      INT8
  LM head:        INT8
  KV cache:       FP8 E4M3

Strategy:
  Expert divisor: -3 (hot_cached_static)
  Prefill threshold: 1
  Mode:           gpu_decode (hot_cached_static)

Prefill (10000 tokens, 3 runs):
  Run 1:  516.2 tok/s, TTFT=19.37s
  Run 2:  527.7 tok/s, TTFT=18.95s
  Run 3:  527.1 tok/s, TTFT=18.97s
  Average: 523.7 tok/s, TTFT=19.10s

Decode (64 tokens, 3 runs):
  Run 1:  7.71 tok/s (129.6ms/tok)
  Run 2:  7.75 tok/s (129.1ms/tok)
  Run 3:  7.66 tok/s (130.6ms/tok)
  Average: 7.71 tok/s (129.8ms/tok)

Verification:
  Prefill prompt: user
Explain distributed consensus algorithms including Paxos, Raft, and PBFT. Describe database transaction isolation levels and their trade-offs. Discuss compiler optimization passes such as dead co... [63136 chars total]
  Decode prompt:  Write a poem about recursion in programming.
  Generated output (64 tokens):
    **The Recursive Ladder**  
    
    A function calls itself—soft and low,  
    A whisper in the code’s deep flow.  
    It checks the base: *“Am I done?  
    If not, I’ll call again, until the run is won.”*  
    
    A stack of frames, like books upright,
================================================================
